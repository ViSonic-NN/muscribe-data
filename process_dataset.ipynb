{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The music data in this repository are combined from ACPAS, A-MAPS, Classical Piano Midi, and ASAP music datasets.\n",
    "See the [PM2S repository](https://github.com/cheriell/PM2S/tree/main/dev) for details.\n",
    "\n",
    "This notebook shows how we processed these music datasets.\n",
    "You don't need to run this notebook again if you just want to use the dataset;\n",
    "the data contained in this repo is already processed.\n",
    "\n",
    "- `pm2s_metadata_r.csv` and `pm2s_metadata_s.csv` come from `dev/metadata/ACPAS/metadata_{R,S}.csv` in the PM2S repo respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 1670 MIDI files\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "meta_r = pd.read_csv(\"./pm2s_metadata_r.csv\")\n",
    "assert len(meta_r[\"performance_MIDI_external\"]) == len(\n",
    "    set(meta_r[\"performance_MIDI_external\"])\n",
    ")\n",
    "meta_s = pd.read_csv(\"./pm2s_metadata_s.csv\")\n",
    "assert len(meta_s[\"performance_MIDI_external\"]) == len(\n",
    "    set(meta_s[\"performance_MIDI_external\"])\n",
    ")\n",
    "# There are no duplicate performance MIDI files in each set,\n",
    "# but cross-set duplicates exist\n",
    "# The \"S\" (synthetic) set has Kontakt instrument-synthesized audio\n",
    "# which we don\"t have access to, nor do we need them.\n",
    "# The MIDI files are the same in the case of duplications.\n",
    "\n",
    "meta = pd.concat([meta_s, meta_r]).reset_index(drop=True)\n",
    "meta.drop_duplicates(\"performance_MIDI_external\", inplace=True)\n",
    "print(f\"Total {meta.shape[0]} MIDI files\")\n",
    "\n",
    "meta.rename(\n",
    "    columns={\n",
    "        \"performance_MIDI_external\": \"perf_midi_file\",\n",
    "        \"MIDI_score_external\": \"orig_midi_file\",\n",
    "        \"performance_annotation_external\": \"annot_file\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "meta.drop(\n",
    "    columns=[\n",
    "        \"performance_id\",\n",
    "        \"performance_audio_external\",\n",
    "        \"score_annotation_external\",\n",
    "        \"folder\",\n",
    "        \"performance_audio\",\n",
    "        \"performance_MIDI\",\n",
    "        \"MIDI_score\",\n",
    "        \"performance_annotation\",\n",
    "        \"score_annotation\",\n",
    "    ],\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# There are a few case-mismatched paths that we'll correct here.\n",
    "remap = {\n",
    "    \"cpm/Schubert/schubert_D850_1.mid\": \"cpm/Schubert/schubert_d850_1.mid\",\n",
    "    \"cpm/Schubert/schubert_D850_2.mid\": \"cpm/Schubert/schubert_d850_2.mid\",\n",
    "    \"cpm/Schubert/schubert_D850_3.mid\": \"cpm/Schubert/schubert_d850_3.mid\",\n",
    "    \"cpm/Schubert/schubert_D850_4.mid\": \"cpm/Schubert/schubert_d850_4.mid\",\n",
    "}\n",
    "\n",
    "\n",
    "def map_annot_path(s: str):\n",
    "    if isinstance(s, str) and \"{ASAP}\" in s:\n",
    "        return s.replace(\"{ASAP}/\", \"asap/\")\n",
    "    assert isinstance(s, float) and s != s  # isnan\n",
    "    return None\n",
    "\n",
    "\n",
    "def map_midi_path(s: str):\n",
    "    if \"{A_MAPS}\" in s:\n",
    "        return s.replace(\"{A_MAPS}/MAPS_MUS-\", \"amaps/\")\n",
    "    if \"{ASAP}\" in s:\n",
    "        return s.replace(\"{ASAP}/\", \"asap/\")\n",
    "    if \"{CPM}\" in s:\n",
    "        s = s.replace(\"{CPM}/midis/\", \"cpm/\")\n",
    "        if s in remap:\n",
    "            s = remap[s]\n",
    "        return s\n",
    "    raise ValueError(f\"Unknown path: {s}\")\n",
    "\n",
    "\n",
    "def read_midi_info(midi_file):\n",
    "    import pretty_midi as pm\n",
    "\n",
    "    midi = pm.PrettyMIDI(midi_file)\n",
    "    duration = midi.get_end_time()\n",
    "    n_notes = np.sum([len(inst.notes) for inst in midi.instruments])\n",
    "    return duration, n_notes\n",
    "\n",
    "\n",
    "def check_all_files_exist(files):\n",
    "    for f in files:\n",
    "        if f is not None and not (f := Path(f)).is_file():\n",
    "            raise ValueError(f\"File not found: {f}\")\n",
    "\n",
    "\n",
    "meta[\"perf_midi_file\"] = meta[\"perf_midi_file\"].map(map_midi_path)\n",
    "meta[\"orig_midi_file\"] = meta[\"orig_midi_file\"].map(map_midi_path)\n",
    "meta[\"annot_file\"] = meta[\"annot_file\"].map(map_annot_path)\n",
    "\n",
    "# There are exactly 2 pieces with wrong duration; we'll overwrite them.\n",
    "# asap/Beethoven/Piano_Sonatas/11-1/MaximovI02M.mid\n",
    "# asap/Beethoven/Piano_Sonatas/9-1/Tysman05M.mid\n",
    "midi_info = meta[\"perf_midi_file\"].map(read_midi_info)\n",
    "meta[\"duration\"], meta[\"n_notes\"] = midi_info.map(lambda x: x[0]), midi_info.map(\n",
    "    lambda x: x[1]\n",
    ")\n",
    "\n",
    "# No need to check \"perf_midi_file\" again -- already loaded these MIDI diles\n",
    "check_all_files_exist(\n",
    "    pd.concat([meta[\"orig_midi_file\"], meta[\"annot_file\"]]).to_numpy()\n",
    ")\n",
    "\n",
    "meta.to_csv(\"metadata.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output format explained:\n",
    "- `perf_midi_file` is the MIDI file of an entry (not necessarily a human performance MIDI; it depends on the dataset)\n",
    "\n",
    "- `orig_midi_file` is the score MIDI file of an entry.\n",
    "  If a piece has multiple performance versions (typically in the `ASAP` dataset), then this points to the non-performance, score-version MIDI of that piece.\n",
    "\n",
    "- `annot_file` points to the annotation file of an entry. This only exists for `ASAP`;\n",
    "  for the other 2 datasets, the annotations are builtin to the MIDI file, and this column's value is `None`.\n",
    "\n",
    "- `aligned` is a boolean and exists in the original metadata. It's not clear what this means, and it does not seem to do anything in PM2S source code.\n",
    "\n",
    "- All file paths are relative to the root of this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pieces</th>\n",
       "      <th>performances</th>\n",
       "      <th>duration</th>\n",
       "      <th>n_notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>359</td>\n",
       "      <td>1155</td>\n",
       "      <td>340844.519229</td>\n",
       "      <td>3456673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>49</td>\n",
       "      <td>135</td>\n",
       "      <td>31208.688997</td>\n",
       "      <td>280316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>89</td>\n",
       "      <td>380</td>\n",
       "      <td>113079.258010</td>\n",
       "      <td>1255614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pieces  performances       duration  n_notes\n",
       "train          359          1155  340844.519229  3456673\n",
       "validation      49           135   31208.688997   280316\n",
       "test            89           380  113079.258010  1255614"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_stats(dataset):\n",
    "    return {\n",
    "        \"pieces\": len(dataset[\"piece_id\"].unique()),\n",
    "        \"performances\": dataset.shape[0],\n",
    "        \"duration\": dataset[\"duration\"].sum(),\n",
    "        \"n_notes\": dataset[\"n_notes\"].sum(),\n",
    "    }\n",
    "\n",
    "\n",
    "meta = pd.read_csv(\"./metadata.csv\")\n",
    "datasets = [\"train\", \"validation\", \"test\"]\n",
    "pd.DataFrame([get_stats(meta[meta[\"split\"] == s]) for s in datasets], index=datasets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "muscribe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
